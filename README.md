# Systematicity

We can differentiate two types of metrics: forward-looking metrics and backward-looking metrics. 

Forward-looking metrics can be calculated when we use the algorithm for making a decision. For example, we can calculate the DEI (diversity, equity, and inclusion) of a company after all available vacancies are filled in and compare it with the DEI target. Forward-looking metrics include distribution analysis and override analysis. Distribution analysis looks at the distribution of algorithmic outputs by certain features that we hypothesize to be relevant for a bias. For example, we can segment applicants by gender, ethnicity or age and calculate their respective hiring rates. Low or no bias would imply similar hiring rates of candidates of different gender, ethnicity, and age. Override analysis would be applicable if hiring process entails some element of override - for example because an HR validates algorithmic decisions. A high override rate is the first indication that an algorithm might have a problem; a deep-dive can indicate whether overrides are concentrated in a particular group of cases. We may be able to pinpoint which model input or logic causes a bias (e.g., if the algorithm has penalized graduates from a non-Ivy League school - this suggests that the algorithm might suffer from an unwarranted preference for Ivy League schools).

Backward-looking metrics are the most direct indicator of a bias. Backward-looking metrics include calibration and rank ordering. Calibration  compares predictions with actual outcomes. For a binary event, such as 'hired', we would compare the average probability given by the algorithm (e.g., for a sample of 100 applicants, the algorithm may indicate an average hiring rate of 15%, which would imply 15 applicants hired) with an actual percentage of cases where the event in question has occurred (e.g., we may have 25 applicants hired, which means that the algorithm under-predicted the number 'hires'). For a continuous outcome, we would compare predictions and outcomes. Rank ordering can be measured by Gini coefficient (for binary outcomes).

I would expand this analysis by collecting more applicant data and repeatedly training models on new data. 
